"""æ¥½å¤©å•†å“ç›£è¦–ãƒ„ãƒ¼ãƒ« ãƒ¡ã‚¤ãƒ³CLI"""
import argparse
import logging
import sys
import time
from datetime import datetime
from typing import List, Dict, Any
import requests
from bs4 import BeautifulSoup
import re

try:
    from .config_loader import ConfigLoader
    from .item_db import ItemDB
    from .discord_notifier import DiscordNotifier
    from .prometheus_client import push_failure_metric, push_monitoring_metric, push_database_metric
    from .exceptions import (
        RakutenMonitorError, 
        LayoutChangeError, 
        DatabaseConnectionError,
        ConfigurationError,
        DiscordNotificationError,
        NetworkError,
        PrometheusError
    )
except ImportError:
    from config_loader import ConfigLoader
    from item_db import ItemDB
    from discord_notifier import DiscordNotifier
    from prometheus_client import push_failure_metric, push_monitoring_metric, push_database_metric
    from exceptions import (
        RakutenMonitorError, 
        LayoutChangeError, 
        DatabaseConnectionError,
        ConfigurationError,
        DiscordNotificationError,
        NetworkError,
        PrometheusError
    )


logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class RakutenMonitor:
    """æ¥½å¤©å•†å“ç›£è¦–ãƒ„ãƒ¼ãƒ«ã®ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config_path: str = "config.json"):
        self.config_loader = ConfigLoader(config_path)
        self.db = None
        self.notifier = None
    
    def _test_database_connection(self) -> bool:
        """PostgreSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’ãƒ†ã‚¹ãƒˆ"""
        try:
            with ItemDB() as db:
                # ç°¡å˜ãªæ¥ç¶šãƒ†ã‚¹ãƒˆ
                db.get_item('test_connection')
                logger.info("PostgreSQLæ¥ç¶šãƒ†ã‚¹ãƒˆæˆåŠŸ")
                return True
        except Exception as e:
            logger.error(f"PostgreSQLæ¥ç¶šãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
            return False
    
    def _is_monitoring_time(self) -> bool:
        """ç¾åœ¨æ™‚åˆ»ãŒç›£è¦–æ™‚é–“å†…ã‹ãƒã‚§ãƒƒã‚¯"""
        now = datetime.now()
        current_time = now.strftime("%H:%M")
        
        start_time = self.config_loader.start_time
        end_time = self.config_loader.end_time
        
        return start_time <= current_time <= end_time
    
    def _extract_product_info(self, url: str, html: str) -> List[Dict[str, Any]]:
        """HTMLã‹ã‚‰å•†å“æƒ…å ±ã‚’æŠ½å‡º"""
        try:
            soup = BeautifulSoup(html, 'html.parser')
            products = []
            
            # æ¥½å¤©å¸‚å ´ã®å•†å“ãƒšãƒ¼ã‚¸ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            if '/item.rakuten.co.jp/' in url:
                # å˜ä¸€å•†å“ãƒšãƒ¼ã‚¸
                product = self._extract_single_product(soup, url)
                if product:
                    products.append(product)
            else:
                # ã‚«ãƒ†ã‚´ãƒªãƒšãƒ¼ã‚¸ - è¤‡æ•°å•†å“
                products = self._extract_multiple_products(soup, url)
            
            if not products:
                raise LayoutChangeError(f"å•†å“æƒ…å ±ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ: {url}")
            
            return products
            
        except Exception as e:
            if isinstance(e, LayoutChangeError):
                raise
            raise LayoutChangeError(f"HTMLè§£æã‚¨ãƒ©ãƒ¼: {e}")
    
    def _extract_single_product(self, soup: BeautifulSoup, url: str) -> Dict[str, Any]:
        """å˜ä¸€å•†å“ãƒšãƒ¼ã‚¸ã‹ã‚‰æƒ…å ±æŠ½å‡º"""
        try:
            # å•†å“å
            name_selectors = [
                'h1[data-testid="item-name"]',
                '.item_name h1',
                'h1.item_name',
                'h1'
            ]
            name = self._find_text_by_selectors(soup, name_selectors)
            
            # ä¾¡æ ¼
            price_selectors = [
                '[data-testid="price"]',
                '.price_value',
                '.price',
                '.item_price'
            ]
            price = self._find_text_by_selectors(soup, price_selectors)
            
            # åœ¨åº«çŠ¶æ³
            stock_selectors = [
                '[data-testid="stock-status"]',
                '.item_stock',
                '.stock_status'
            ]
            stock_text = self._find_text_by_selectors(soup, stock_selectors)
            
            # åœ¨åº«çŠ¶æ³ã®åˆ¤å®š
            if stock_text and any(keyword in stock_text for keyword in ['å£²ã‚Šåˆ‡ã‚Œ', 'åœ¨åº«ãªã—', 'å“åˆ‡ã‚Œ']):
                status = 'å£²ã‚Šåˆ‡ã‚Œ'
            else:
                status = 'åœ¨åº«ã‚ã‚Š'
            
            # å•†å“IDã‚’ç”Ÿæˆï¼ˆURLã‹ã‚‰ï¼‰
            product_id = self._extract_product_id_from_url(url)
            
            return {
                'product_id': product_id,
                'name': name or 'Unknown Product',
                'price': price or 'ä¾¡æ ¼ä¸æ˜',
                'status': status,
                'url': url
            }
            
        except Exception as e:
            logger.warning(f"Single product extraction failed: {e}")
            return None
    
    def _extract_multiple_products(self, soup: BeautifulSoup, url: str) -> List[Dict[str, Any]]:
        """ã‚«ãƒ†ã‚´ãƒªãƒšãƒ¼ã‚¸ã‹ã‚‰è¤‡æ•°å•†å“æƒ…å ±æŠ½å‡º"""
        products = []
        
        # æ¥½å¤©å¸‚å ´ã®ã‚«ãƒ†ã‚´ãƒªãƒšãƒ¼ã‚¸ã®å•†å“ã‚¢ã‚¤ãƒ†ãƒ 
        item_selectors = [
            '.searchresultitem',
            '.item',
            '.product'
        ]
        
        items = []
        for selector in item_selectors:
            items = soup.select(selector)
            if items:
                break
        
        for item in items[:20]:  # æœ€å¤§20ä»¶ã«åˆ¶é™
            try:
                # å•†å“ãƒªãƒ³ã‚¯
                link_elem = item.select_one('a[href*="/item.rakuten.co.jp/"]')
                if not link_elem:
                    continue
                
                product_url = link_elem.get('href')
                if not product_url.startswith('http'):
                    product_url = 'https:' + product_url
                
                # å•†å“å
                name_elem = item.select_one('.itemname, .item_name, h3')
                name = name_elem.get_text(strip=True) if name_elem else 'Unknown Product'
                
                # ä¾¡æ ¼
                price_elem = item.select_one('.price, .item_price')
                price = price_elem.get_text(strip=True) if price_elem else 'ä¾¡æ ¼ä¸æ˜'
                
                # åœ¨åº«çŠ¶æ³ï¼ˆç°¡æ˜“åˆ¤å®šï¼‰
                item_text = item.get_text()
                if any(keyword in item_text for keyword in ['å£²ã‚Šåˆ‡ã‚Œ', 'åœ¨åº«ãªã—', 'å“åˆ‡ã‚Œ']):
                    status = 'å£²ã‚Šåˆ‡ã‚Œ'
                else:
                    status = 'åœ¨åº«ã‚ã‚Š'
                
                product_id = self._extract_product_id_from_url(product_url)
                
                products.append({
                    'product_id': product_id,
                    'name': name,
                    'price': price,
                    'status': status,
                    'url': product_url
                })
                
            except Exception as e:
                logger.warning(f"Failed to extract product from item: {e}")
                continue
        
        return products
    
    def _find_text_by_selectors(self, soup: BeautifulSoup, selectors: List[str]) -> str:
        """è¤‡æ•°ã®ã‚»ãƒ¬ã‚¯ã‚¿ã‹ã‚‰æœ€åˆã«ãƒãƒƒãƒã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—"""
        for selector in selectors:
            elem = soup.select_one(selector)
            if elem:
                return elem.get_text(strip=True)
        return ""
    
    def _extract_product_id_from_url(self, url: str) -> str:
        """URLã‹ã‚‰å•†å“IDã‚’æŠ½å‡º"""
        # URLã‹ã‚‰å•†å“IDã‚‰ã—ãéƒ¨åˆ†ã‚’æŠ½å‡º
        match = re.search(r'/([^/]+)/?$', url.rstrip('/'))
        if match:
            return match.group(1)
        return url.split('/')[-1] or 'unknown'
    
    def _extract_price_number(self, price_str: str) -> int:
        """ä¾¡æ ¼æ–‡å­—åˆ—ã‹ã‚‰æ•°å€¤ã‚’æŠ½å‡º"""
        try:
            # æ•°å­—ä»¥å¤–ã‚’é™¤å»
            price_num = re.sub(r'[^\d]', '', price_str)
            return int(price_num) if price_num else 0
        except (ValueError, TypeError):
            return 0
    
    def _fetch_page(self, url: str) -> str:
        """Webãƒšãƒ¼ã‚¸ã‚’å–å¾—"""
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            response = requests.get(url, headers=headers, timeout=30)
            response.raise_for_status()
            response.encoding = response.apparent_encoding
            return response.text
        except requests.exceptions.Timeout as e:
            raise NetworkError(f"ãƒšãƒ¼ã‚¸å–å¾—ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {e}", url=url, timeout=True)
        except requests.exceptions.ConnectionError as e:
            raise NetworkError(f"ãƒšãƒ¼ã‚¸æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}", url=url, timeout=False)
        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 404:
                raise LayoutChangeError(f"ãƒšãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ (404): {url}")
            elif e.response.status_code >= 500:
                raise NetworkError(f"ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼ ({e.response.status_code}): {e}", url=url)
            else:
                raise NetworkError(f"HTTPã‚¨ãƒ©ãƒ¼ ({e.response.status_code}): {e}", url=url)
        except requests.RequestException as e:
            raise NetworkError(f"ãƒšãƒ¼ã‚¸å–å¾—ã‚¨ãƒ©ãƒ¼: {e}", url=url)
    
    def _process_url(self, url: str) -> List[Dict[str, str]]:
        """å˜ä¸€URLã‚’å‡¦ç†ã—ã¦å¤‰æ›´ã‚’æ¤œå‡º"""
        try:
            logger.info(f"Processing URL: {url}")
            html = self._fetch_page(url)
            products = self._extract_product_info(url, html)
            
            changes = []
            with ItemDB() as db:
                for product in products:
                    # PostgreSQLç”¨ã«item_codeã‚’ç”Ÿæˆ
                    item_code = f"{product['url']}_{product['product_id']}"
                    
                    # æ—¢å­˜ã‚¢ã‚¤ãƒ†ãƒ ã®ç¢ºèª
                    existing_item = db.get_item(item_code)
                    
                    # ã‚¢ã‚¤ãƒ†ãƒ ã‚’ä¿å­˜
                    item_dict = {
                        'item_code': item_code,
                        'title': product['name'],
                        'price': self._extract_price_number(product['price']),
                        'status': product['status']
                    }
                    db.save_item(item_dict)
                    
                    # å¤‰æ›´æ¤œå‡º
                    if not existing_item:
                        if product['status'] == 'åœ¨åº«ã‚ã‚Š':
                            changes.append({
                                'change_type': 'new_item',
                                'name': product['name'],
                                'price': product['price'],
                                'status': product['status'],
                                'url': product['url']
                            })
                    elif existing_item['status'] == 'å£²ã‚Šåˆ‡ã‚Œ' and product['status'] == 'åœ¨åº«ã‚ã‚Š':
                        changes.append({
                            'change_type': 'restock',
                            'name': product['name'],
                            'price': product['price'],
                            'status': product['status'],
                            'url': product['url']
                        })
            
            return changes
            
        except LayoutChangeError as e:
            logger.error(f"Layout change detected: {e}")
            # Discord è­¦å‘Šé€šçŸ¥
            if self.notifier:
                try:
                    self.notifier.send_warning(
                        title="ãƒšãƒ¼ã‚¸æ§‹é€ å¤‰æ›´",
                        message="æ¥½å¤©å¸‚å ´ã®ãƒšãƒ¼ã‚¸æ§‹é€ ãŒå¤‰æ›´ã•ã‚ŒãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚",
                        details=f"URL: {url}\nã‚¨ãƒ©ãƒ¼: {str(e)}"
                    )
                except DiscordNotificationError as discord_err:
                    logger.error(f"Failed to send Discord warning: {discord_err}")
            
            # Prometheus ãƒ¡ãƒˆãƒªã‚¯ã‚¹é€ä¿¡
            try:
                push_failure_metric("layout", str(e))
            except PrometheusError as prom_err:
                logger.error(f"Failed to push layout error metric: {prom_err}")
            
            raise
        except DatabaseConnectionError as e:
            logger.error(f"Database connection failed: {e}")
            # Discord é‡å¤§ã‚¨ãƒ©ãƒ¼é€šçŸ¥
            if self.notifier:
                try:
                    self.notifier.send_critical(
                        title="ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼",
                        message="PostgreSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚",
                        details=str(e)
                    )
                except DiscordNotificationError as discord_err:
                    logger.error(f"Failed to send Discord critical alert: {discord_err}")
            
            # Prometheus ãƒ¡ãƒˆãƒªã‚¯ã‚¹é€ä¿¡
            try:
                push_failure_metric("db", str(e))
            except PrometheusError as prom_err:
                logger.error(f"Failed to push database error metric: {prom_err}")
            
            raise
        except NetworkError as e:
            logger.error(f"Network error: {e}")
            # Discord è­¦å‘Šé€šçŸ¥
            if self.notifier:
                try:
                    self.notifier.send_warning(
                        title="ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼",
                        message="æ¥½å¤©å¸‚å ´ã¸ã®æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸã€‚",
                        details=f"URL: {e.url or url}\nã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {'Yes' if e.timeout else 'No'}\nã‚¨ãƒ©ãƒ¼: {str(e)}"
                    )
                except DiscordNotificationError as discord_err:
                    logger.error(f"Failed to send Discord network warning: {discord_err}")
            
            # Prometheus ãƒ¡ãƒˆãƒªã‚¯ã‚¹é€ä¿¡
            try:
                push_failure_metric("network", str(e))
            except PrometheusError as prom_err:
                logger.error(f"Failed to push network error metric: {prom_err}")
            
            raise
        except Exception as e:
            logger.error(f"URL processing failed: {e}")
            # äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ã®å ´åˆã‚‚ Discord ã«é€šçŸ¥
            if self.notifier:
                try:
                    self.notifier.send_critical(
                        title="äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼",
                        message="å•†å“å‡¦ç†ä¸­ã«äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚",
                        details=f"URL: {url}\nã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—: {type(e).__name__}\nã‚¨ãƒ©ãƒ¼: {str(e)}"
                    )
                except DiscordNotificationError as discord_err:
                    logger.error(f"Failed to send Discord unexpected error alert: {discord_err}")
            
            # Prometheus ãƒ¡ãƒˆãƒªã‚¯ã‚¹é€ä¿¡
            try:
                push_failure_metric("unexpected", str(e))
            except PrometheusError as prom_err:
                logger.error(f"Failed to push unexpected error metric: {prom_err}")
            
            raise
    
    def run_monitoring(self) -> None:
        """ç›£è¦–ã‚’å®Ÿè¡Œ"""
        start_time = time.time()
        items_processed = 0
        changes_found = 0
        
        try:
            # è¨­å®šèª­ã¿è¾¼ã¿
            config = self.config_loader.load_config()
            self.notifier = DiscordNotifier(config['webhookUrl'])
            
            # ç›£è¦–æ™‚é–“ãƒã‚§ãƒƒã‚¯
            if not self._is_monitoring_time():
                logger.info("Outside monitoring hours, exiting quietly")
                return
            
            logger.info("Starting Rakuten item monitoring")
            
            all_changes = []
            urls_to_process = config['urls']
            
            for url in urls_to_process:
                try:
                    changes = self._process_url(url)
                    all_changes.extend(changes)
                    items_processed += 1
                except LayoutChangeError as e:
                    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆå¤‰æ›´ã‚¨ãƒ©ãƒ¼ã¯æ—¢ã« _process_url ã§å‡¦ç†æ¸ˆã¿
                    logger.error(f"Layout change detected for {url}: {e}")
                    continue
                except DatabaseConnectionError as e:
                    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã¯æ—¢ã« _process_url ã§å‡¦ç†æ¸ˆã¿
                    logger.error(f"Database error for {url}: {e}")
                    continue
                except NetworkError as e:
                    # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ã¯æ—¢ã« _process_url ã§å‡¦ç†æ¸ˆã¿
                    logger.error(f"Network error for {url}: {e}")
                    continue
                except Exception as e:
                    logger.error(f"Unexpected error processing {url}: {e}")
                    continue
            
            changes_found = len(all_changes)
            
            # é€šçŸ¥é€ä¿¡
            discord_failures = 0
            for change in all_changes:
                try:
                    if change['change_type'] == 'new_item':
                        self.notifier.notify_new_item(change)
                    elif change['change_type'] == 'restock':
                        self.notifier.notify_restock(change)
                except DiscordNotificationError as e:
                    discord_failures += 1
                    logger.error(f"Failed to send notification: {e}")
                    # Discordéšœå®³ã‚’Prometheusã«è¨˜éŒ²
                    try:
                        push_failure_metric("discord", str(e))
                    except PrometheusError as prom_err:
                        logger.error(f"Failed to push Discord error metric: {prom_err}")
            
            # Discordé€šçŸ¥å¤±æ•—ãŒå¤šã„å ´åˆã¯è­¦å‘Š
            if discord_failures > 0:
                logger.warning(f"Discord notification failures: {discord_failures}/{len(all_changes)}")
                if discord_failures >= len(all_changes) // 2:  # åŠæ•°ä»¥ä¸Šå¤±æ•—
                    try:
                        self.notifier.send_critical(
                            title="Discordé€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ éšœå®³",
                            message=f"Discordé€šçŸ¥ã®é€ä¿¡ã«è¤‡æ•°å›å¤±æ•—ã—ã¾ã—ãŸ ({discord_failures}/{len(all_changes)})ã€‚",
                            details="Discord Webhookã®è¨­å®šã‚„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
                        )
                    except DiscordNotificationError:
                        # Discordè‡ªä½“ãŒæ­»ã‚“ã§ã‚‹å ´åˆã¯ãƒ­ã‚°ã®ã¿
                        logger.critical("Critical: Discord notification system appears to be down")
            
            # ç›£è¦–å®Œäº†ãƒ¡ãƒˆãƒªã‚¯ã‚¹é€ä¿¡
            duration = time.time() - start_time
            try:
                push_monitoring_metric(items_processed, changes_found, duration)
            except PrometheusError as e:
                logger.error(f"Failed to push monitoring metrics: {e}")
            
            logger.info(f"Monitoring completed. Processed {items_processed} URLs, found {changes_found} changes in {duration:.2f}s")
            
        except ConfigurationError as e:
            logger.error(f"Configuration error: {e}")
            sys.exit(1)
        except DatabaseConnectionError as e:
            logger.error(f"Database error: {e}")
            if hasattr(self, 'notifier') and self.notifier:
                self.notifier.notify_error("db", str(e))
            sys.exit(1)
        except Exception as e:
            logger.error(f"Unexpected error: {e}")
            sys.exit(1)


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(description='æ¥½å¤©å•†å“ç›£è¦–ãƒ„ãƒ¼ãƒ«')
    parser.add_argument('--config', default='config.json', help='è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹')
    parser.add_argument('--cron', action='store_true', help='cronå®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰')
    parser.add_argument('--test', action='store_true', help='æ¥ç¶šãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰')
    
    args = parser.parse_args()
    
    try:
        monitor = RakutenMonitor(args.config)
        
        if args.test:
            # æ¥ç¶šãƒ†ã‚¹ãƒˆ
            print("=== PostgreSQL & Discord æ¥ç¶šãƒ†ã‚¹ãƒˆ ===")
            
            # PostgreSQLæ¥ç¶šãƒ†ã‚¹ãƒˆ
            if monitor._test_database_connection():
                print("âœ… PostgreSQLæ¥ç¶šãƒ†ã‚¹ãƒˆæˆåŠŸ")
                db_success = True
            else:
                print("âŒ PostgreSQLæ¥ç¶šãƒ†ã‚¹ãƒˆå¤±æ•—")
                db_success = False
            
            # Discordæ¥ç¶šãƒ†ã‚¹ãƒˆ
            try:
                config = monitor.config_loader.load_config()
                notifier = DiscordNotifier(config['webhookUrl'])
                if notifier.test_connection():
                    print("âœ… Discordæ¥ç¶šãƒ†ã‚¹ãƒˆæˆåŠŸ")
                    discord_success = True
                else:
                    print("âŒ Discordæ¥ç¶šãƒ†ã‚¹ãƒˆå¤±æ•—")
                    discord_success = False
            except Exception as e:
                print(f"âŒ Discordæ¥ç¶šãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
                discord_success = False
            
            # çµæœã‚µãƒãƒªãƒ¼
            if db_success and discord_success:
                print("\nğŸ‰ ã™ã¹ã¦ã®æ¥ç¶šãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸ")
                sys.exit(0)
            else:
                print("\nâš ï¸  ä¸€éƒ¨ã®æ¥ç¶šãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸ")
                sys.exit(1)
        else:
            # é€šå¸¸ã®ç›£è¦–å®Ÿè¡Œ (cron/å¯¾è©±çš„å®Ÿè¡Œå…±é€š)
            if args.cron:
                # cronãƒ¢ãƒ¼ãƒ‰: ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’èª¿æ•´
                logging.getLogger().setLevel(logging.WARNING)
                logger.info("Running in cron mode")
            
            monitor.run_monitoring()
            
    except KeyboardInterrupt:
        logger.info("Monitoring interrupted by user")
    except Exception as e:
        logger.error(f"Fatal error: {e}")
        sys.exit(1)


if __name__ == '__main__':
    main()